{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ed8968-da90-4ba1-a121-1902a16be634",
   "metadata": {},
   "source": [
    "# Part 1: LLM – Exploratory Data Analysis & Missing Data Imputation\r\n",
    "\r\n",
    "In **Part 1**, we begin our Final Project into the SAP product dataset provided by Kärcher. Our goal is to prepare and enrich this data for downstream interactions with a large language model (LLM). The steps in this phase are:\r\n",
    "\r\n",
    "1. **Classical Exploratory Data Analysis (EDA)**\r\n",
    "   - Load and inspect the raw dataset extract from SAP.\r\n",
    "   - Examine each field’s data type, distribution, and cardinality.\r\n",
    "   - Compute basic descriptive statistics to gain a holistic view of the dataset.\r\n",
    "\r\n",
    "2. **Data Transformation for LLM Consumption**\r\n",
    "   - Convert original “object”-typed fields into appropriate **categorical** or **numerical** types.\r\n",
    "   - Document all transformation rules and mappings to ensure reproducibility.\r\n",
    "\r\n",
    "3. **Missing Data Identification & Imputation Strategy**\r\n",
    "   - Identify records and cells with missing values in critical fields.\r\n",
    "   - Leverage the **product description PDFs** (extracted in Part 0 using agentic embeddings) as our external knowledge source.\r\n",
    "   - Query the IBM Granite 13B Instruct V2 model to cross-reference the markdowns from Part 0 and suggest imputed values for each missing field.\r\n",
    "\r\n",
    "4. **Validation & Iteration**\r\n",
    "   - Cross-check the LLM’s imputations against ground-truth data or manual inspection of the source PDFs.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf34e0-f71c-40f9-bc82-a29497dc5290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57423594-7da5-41e4-9a1d-cbc305ddeba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import difflib \n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a733b6a-1f63-4100-8c0a-ec5792904c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd()  \n",
    "data_file    = project_root / \"data\" / \"SAP_Produktstammdaten_vfinal.csv\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    data_file,\n",
    "    sep=\",\",                # comma-separated\n",
    "    engine=\"python\",        # tolerant parser\n",
    "    quotechar='\"',          # respect commas inside quotes\n",
    "    skipinitialspace=True,  # trim spaces after delimiters\n",
    "    dtype=str               # load all as strings initially\n",
    ")\n",
    "\n",
    "original = df.copy(deep=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7bd58-39e6-448b-af43-fe86381531b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumn types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0826ed0-93ce-4fde-be15-61c91e8afa85",
   "metadata": {},
   "source": [
    "In order to proceed with data manipulation we would need to change the types of the data in order to be able to perfom manipulations that would not be possible if numbers are stored as string value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285165ba-36fb-4e3d-b2a1-6f96ebc32f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"Preis (€ inkl. MwSt.)\",\n",
    "    \"Flächenleistung (m²/h)\",\n",
    "    \"Anschlussleistung (kW)\",\n",
    "    \"Anschlusskabel (m)\",\n",
    "    \"Gewicht ohne Zubehör (kg)\",\n",
    "    \"Gewicht inkl. Verpackung (kg)\"\n",
    "]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    # German‐style decimals: comma → dot\n",
    "    cleaned = (\n",
    "        df[col]\n",
    "        .str.replace(r\"[^\\d,.\\-]\", \"\", regex=True)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    df[col] = pd.to_numeric(cleaned, errors=\"coerce\")\n",
    "\n",
    "cat_cols = [c for c in df.columns if c not in numeric_cols]\n",
    "df[cat_cols] = df[cat_cols].astype(\"category\")\n",
    "\n",
    "print(df.dtypes)\n",
    "print(df[numeric_cols].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe00a5-5121-4b67-951e-fa1a6f8be160",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2d907c-e6ab-49ee-9b9a-110896bcd1b9",
   "metadata": {},
   "source": [
    "As we can see, some of the data is already missing, lets increase the number of missing data by blanking 10%, this will give us the possibility to check the accuracy of the LLM performance at the end as we know the \"banked\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a0abb-ffeb-4762-9b04-205f333e7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy(deep=True)\n",
    "\n",
    "n_rows, n_cols = df_test.shape\n",
    "total_cells     = n_rows * n_cols\n",
    "n_blanks        = int(total_cells * 0.1)\n",
    "\n",
    "\n",
    "product_col = df_test.columns.get_loc(\"Produktname\")\n",
    "\n",
    "# Builds a list of all flat indices except those in Produktname\n",
    "# For each row r and column c ≠ product_col, flat_index = r*n_cols + c\n",
    "valid_indices = [\n",
    "    r * n_cols + c\n",
    "    for r in range(n_rows)\n",
    "    for c in range(n_cols)\n",
    "    if c != product_col\n",
    "]\n",
    "\n",
    "# Picks 10% of those valid positions at random (reproducibly)\n",
    "rng = np.random.default_rng(seed=42)\n",
    "flat_indices = rng.choice(valid_indices, size=n_blanks, replace=False)\n",
    "\n",
    "# Maps flat indices back to (row, col) and set to NaN\n",
    "for idx in flat_indices:\n",
    "    i = idx // n_cols      # row index\n",
    "    j = idx %  n_cols      # col index\n",
    "    df_test.iat[i, j] = np.nan\n",
    "\n",
    "# Save to a new CSV (ensure your `data/processed` folder exists)\n",
    "out_path = project_root / \"data\" / \"processed\" / \"SAP_Produktstammdaten_vfinal_test_missing.csv\"\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_test.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Test CSV with 10% random blanks written to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f5fa57-b3f2-4a53-bc0f-8f6a45201856",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd()  \n",
    "data_file    = project_root / \"data\" / \"processed\" / \"SAP_Produktstammdaten_vfinal_test_missing.csv\"\n",
    "df_test = pd.read_csv(\n",
    "    data_file,\n",
    "    sep=\",\",                \n",
    "    engine=\"python\",        \n",
    "    quotechar='\"',          \n",
    "    skipinitialspace=True,  \n",
    "    dtype=str               \n",
    ")\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d8f4e-12e6-419f-96f7-527ec296f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd()\n",
    "test_csv     = project_root / \"data\" / \"processed\" / \"SAP_Produktstammdaten_vfinal_test_missing.csv\"\n",
    "df_test      = pd.read_csv(test_csv, sep=\",\", engine=\"python\", quotechar='\"', skipinitialspace=True)\n",
    "\n",
    "missing_locs = [\n",
    "    (i, col)\n",
    "    for i, row in df_test.iterrows()\n",
    "    for col in df_test.columns\n",
    "    if pd.isna(row[col])\n",
    "]\n",
    "print(f\"Found {len(missing_locs)} missing cells. Sample:\")\n",
    "print(missing_locs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a390052-4021-4b57-88bb-d0bb382f2434",
   "metadata": {},
   "source": [
    "Great. The display data is hard to be viewed. We need to find a way to structure the missing data in order to make the work with the LLM easyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f9d2a-9bab-48e7-91ef-dad3d760825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd()\n",
    "test_csv     = project_root / \"data\" / \"processed\" / \"SAP_Produktstammdaten_vfinal_test_missing.csv\"\n",
    "df_test      = pd.read_csv(test_csv, sep=\",\", engine=\"python\",\n",
    "                           quotechar='\"', skipinitialspace=True)\n",
    "\n",
    "cols = [c for c in df_test.columns if c != \"Produktname\"]\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    missing = [c for c in cols if pd.isna(row[c])]\n",
    "    if missing:\n",
    "        prod = row[\"Produktname\"]\n",
    "        print(f\"In {prod} we are missing: {', '.join(missing)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc67295-bcf2-4ee0-814d-8d95c34f4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd()\n",
    "csv_path     = project_root / \"data\" / \"processed\" / \"SAP_Produktstammdaten_vfinal_test_missing.csv\"\n",
    "df_test      = pd.read_csv(csv_path, sep=\",\", engine=\"python\", quotechar='\"', skipinitialspace=True)\n",
    "\n",
    "cols = [c for c in df_test.columns if c != \"Produktname\"]\n",
    "product = None\n",
    "fields  = None\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    missing = [c for c in cols if pd.isna(row[c])]\n",
    "    if missing:\n",
    "        product = row[\"Produktname\"]\n",
    "        fields  = missing\n",
    "        break\n",
    "\n",
    "print(f\"Product with missing data: {product}\")\n",
    "print(f\"Missing fields: {fields}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b1fa75-b7df-4db0-8f12-bd28a9b3bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "from ibm_watsonx_ai import APIClient\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.foundation_models.schema import TextGenParameters\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "WX_API_KEY = \"Kmvh0N6KGE3Rq2eJtOSZOgA_0n3oEUEZhbqd5w0fyGRd\"\n",
    "PROJECT_ID = \"d0c9b183-186c-4eaf-96dc-d8e4285fe71b\"\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key=WX_API_KEY\n",
    ")\n",
    "client = APIClient(credentials=credentials, project_id=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba296d66-4d9e-4617-9896-fa7e332eb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = TextGenParameters(\n",
    "    temperature=0,\n",
    "    max_new_tokens=50,\n",
    "    stop_sequences=[\"\\n\"]\n",
    ")\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
    "    params=PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527392f-53ec-4e6a-b527-567a306575f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dir = project_root / \"parsed_markdown\"\n",
    "descriptions = {}\n",
    "for md in desc_dir.glob(\"*.md\"):\n",
    "    product = md.stem \n",
    "    text    = (md.read_text(encoding=\"utf-8\"))\n",
    "    descriptions[product] = text\n",
    "\n",
    "print(\"Loaded descriptions for\", len(descriptions), \"products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f9398-6d37-4b3c-afb6-f7b1a5d34e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert product-data imputer.\n",
    "\n",
    "Im giving you:\n",
    "\n",
    "  1. The name of exactly *one* field that is missing: {col}\n",
    "  2. The product name: {product}\n",
    "  3. A list of all *other* fields and values in the row\n",
    "  4. A full raw markdown dump\n",
    "\n",
    "Your **only** job is to return *exactly* one thing: the *value* for {col}.\n",
    "- **No** explanations, **no** punctuation around it, **no** units.\n",
    "- If you cannot confidently infer it, return **NA**.\n",
    "\n",
    "Here is the data:\n",
    "\n",
    "Field: {col}  \n",
    "Product: {product}  \n",
    "\n",
    "Known fields:  \n",
    "{other_fields}\n",
    "\n",
    "Raw markdown:  \n",
    "{markdown}\n",
    "\"\"\"\n",
    "\n",
    "# Copy your test DataFrame and locate all missing cells\n",
    "filled = df_test.copy()\n",
    "missing_locs = [\n",
    "    (i, col)\n",
    "    for i, row in df_test.iterrows()\n",
    "    for col in df_test.columns\n",
    "    if pd.isna(row[col])\n",
    "]\n",
    "\n",
    "# Helper to safely grab a number from the model’s text\n",
    "def extract_first_number(s: str) -> float:\n",
    "    m = re.search(r\"-?\\d+(?:[.,]\\d+)?\", s)\n",
    "    return float(m.group(0).replace(\",\", \".\")) if m else np.nan\n",
    "\n",
    "# Loop through each missing cell and call the model\n",
    "for (i, col) in missing_locs:\n",
    "    product = filled.at[i, \"Produktname\"] or \"\"\n",
    "    other_fields = \"\\n\".join(\n",
    "        f\"- {c}: {filled.at[i, c]}\"\n",
    "        for c in filled.columns\n",
    "        if c != col and pd.notna(filled.at[i, c])\n",
    "    )\n",
    "    raw_md = descriptions.get(product, \"\")\n",
    "\n",
    "    prompt = PROMPT_TEMPLATE.format(\n",
    "        col=col,\n",
    "        product=product,\n",
    "        other_fields=other_fields,\n",
    "        markdown=raw_md\n",
    "    )\n",
    "\n",
    "    # Send the prompt\n",
    "    resp = model.generate(prompt)\n",
    "    raw_guess = resp[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # Fill in either as a number or as raw text/NA\n",
    "    if col in numeric_cols:\n",
    "        guess = extract_first_number(raw_guess)\n",
    "    else:\n",
    "        guess = raw_guess or \"NA\"\n",
    "\n",
    "    filled.iat[i, filled.columns.get_loc(col)] = guess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef64ae83-68e9-4471-9d49-523296ea88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i, col in missing_locs:\n",
    "    records.append({\n",
    "        'Field':   col,\n",
    "        'Imputed': filled.at[i, col],\n",
    "        'Actual':  df.at[i, col]\n",
    "    })\n",
    "\n",
    "compare_df = pd.DataFrame(records, columns=['Field','Imputed','Actual'])\n",
    "print(compare_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f0b2b7-e2bb-46fe-b553-a97f85757d28",
   "metadata": {},
   "source": [
    "We can already read that the model is halucinating. Lets format the output in order to make it easyer to analyse visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb65e4-d9a2-4564-9a7d-9a63396b0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# after you’ve built `compare_df`:\n",
    "display(compare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485da2d-021d-4523-8aea-d5ddf50b37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches = compare_df[\n",
    "    compare_df['Imputed'].astype(str) != compare_df['Actual'].astype(str)\n",
    "]\n",
    "display(mismatches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c99ab-ba67-4193-844a-8c4c946eb73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_counts = mismatches.groupby('Field').size().sort_values(ascending=False)\n",
    "print(error_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d505ca88-fbb1-4180-828b-aa869b163a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_correct = len(correct)\n",
    "n_total   = len(compare_df)\n",
    "print(f\"Correct imputations: {n_correct}/{n_total} ({n_correct/n_total:.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3e030-ce1d-4893-8b04-8603b0a50671",
   "metadata": {},
   "source": [
    "As we can see, no correct imput was correct. We can also see that the model returned for some of the fields the name of the category as value (e.g.: Abmessungen (L × B × H) (mm)\tAbmessungen (L × B × H) (mm)). Lets change our promt in order to see if we can get rid of the halucination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef09f5f-2164-4c75-aae9-20ba2f01ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_SYSTEM = \"\"\"\n",
    "You are an expert product-data imputer.\n",
    "When asked for a single missing field, return exactly one token: the missing value and nothing else (no quotes, no units, no explanation). If you cannot determine it, respond with NA. Always use dot for decimals.\n",
    "\"\"\"\n",
    "\n",
    "FEW_SHOT_TEXT = \"\"\"\n",
    "### EXAMPLE 1\n",
    "Field: Druck (bar/MPa)  (type: numeric)\n",
    "Product: K 2 Battery\n",
    "Markdown:\n",
    "### Description\n",
    "A portable battery washer …\n",
    "\n",
    "## Technische Daten\n",
    "- Druck (bar/MPa): max. 110\n",
    "- Fördermenge (l/h): 340\n",
    "\n",
    "→ 110\n",
    "\n",
    "### EXAMPLE 2\n",
    "Field: Farbe  (type: categorical)\n",
    "Product: K 7 Premium Power Flex\n",
    "Markdown:\n",
    "### Description\n",
    "Yellow-and-black pressure washer …\n",
    "\n",
    "## Technische Daten\n",
    "- Gewicht ohne Zubehör (kg): 17.8\n",
    "- Gewicht inkl. Verpackung (kg): 22.2\n",
    "\n",
    "→ gelb\n",
    "\"\"\"\n",
    "\n",
    "# 2) Copy df_test & find missing cells\n",
    "filled = df_test.copy()\n",
    "missing_locs = [\n",
    "    (i, col)\n",
    "    for i, row in df_test.iterrows()\n",
    "    for col in df_test.columns\n",
    "    if pd.isna(row[col])\n",
    "]\n",
    "\n",
    "# 3) Helper to extract a number\n",
    "def extract_first_number(s: str) -> float:\n",
    "    m = re.search(r\"-?\\d+(?:[.,]\\d+)?\", s)\n",
    "    return float(m.group(0).replace(\",\", \".\")) if m else np.nan\n",
    "\n",
    "# 4) Loop & impute\n",
    "for (i, col) in missing_locs:\n",
    "    product = filled.at[i, \"Produktname\"] or \"\"\n",
    "    dtype   = \"numeric\" if col in numeric_cols else \"categorical\"\n",
    "    other   = \"\\n\".join(f\"- {c}: {filled.at[i,c]}\" \n",
    "                        for c in filled.columns \n",
    "                        if c != col and pd.notna(filled.at[i,c]))\n",
    "    md      = descriptions.get(product, \"\")\n",
    "\n",
    "    # 5) Assemble one big prompt string\n",
    "    prompt_text = \"\\n\".join([\n",
    "        BASE_SYSTEM,\n",
    "        FEW_SHOT_TEXT,\n",
    "        f\"### YOUR TURN\",\n",
    "        f\"Field: {col}  (type: {dtype})\",\n",
    "        f\"Product: {product}\",\n",
    "        \"Markdown:\",\n",
    "        md,\n",
    "        \"Other fields:\",\n",
    "        other,\n",
    "        \"→\"\n",
    "    ])\n",
    "\n",
    "    # 6) Call the model with a single string\n",
    "    resp = model.generate(prompt=prompt_text)\n",
    "    raw = resp[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # 7) Coerce numeric vs categorical\n",
    "    if col in numeric_cols:\n",
    "        guess = extract_first_number(raw)\n",
    "    else:\n",
    "        guess = raw or \"NA\"\n",
    "\n",
    "    filled.iat[i, filled.columns.get_loc(col)] = guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731595d5-4ffe-4a8a-ae4b-6424368357cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i, col in missing_locs:\n",
    "    records.append({\n",
    "        'Field':   col,\n",
    "        'Imputed': filled.at[i, col],\n",
    "        'Actual':  df.at[i, col]\n",
    "    })\n",
    "\n",
    "compare_df = pd.DataFrame(records, columns=['Field','Imputed','Actual'])\n",
    "print(compare_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818aed19-0c3d-4613-828e-d96c3fb0e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(compare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591bda5-1f24-4897-9c4c-529c374a544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches = compare_df[\n",
    "    compare_df['Imputed'].astype(str) != compare_df['Actual'].astype(str)\n",
    "]\n",
    "display(mismatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3363009f-627d-4fd2-81b1-88f636637149",
   "metadata": {},
   "source": [
    "The model is obviously halucinating. Lets be deterministic and try to find the value only for the first missing cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858214f5-c241-4734-8f28-778fe0ff301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd()\n",
    "csv_path     = project_root / \"data/processed/SAP_Produktstammdaten_vfinal_test_missing.csv\"\n",
    "clean_dir    = project_root / \"parsed_markdown\"\n",
    "\n",
    "df = pd.read_csv(csv_path, sep=\",\", engine=\"python\", quotechar='\"', skipinitialspace=True)\n",
    "cols = [c for c in df.columns if c != \"Produktname\"]\n",
    "\n",
    "product = field = None\n",
    "for _, row in df.iterrows():\n",
    "    missing = [c for c in cols if pd.isna(row[c])]\n",
    "    if missing:\n",
    "        product = row[\"Produktname\"]\n",
    "        field   = missing[0]\n",
    "        break\n",
    "\n",
    "assert product and field, \"No missing field found!\"\n",
    "\n",
    "md_path = clean_dir / f\"{product}.md\"\n",
    "md_text = md_path.read_text(encoding=\"utf-8\") if md_path.exists() else \"\"\n",
    "\n",
    "BASE_SYSTEM = \"\"\"\n",
    "You are an expert product-data imputer.\n",
    "When asked for a single missing field, you will:\n",
    "1. Read the cleaned Markdown file named <Produktname>.md from parsed_markdown_clean.\n",
    "2. Find the requested field.\n",
    "3. Return exactly one line:\n",
    "In <Produktname> the correct <Field> is <Value>\n",
    "If the field is absent, return:\n",
    "In <Produktname> the correct <Field> is NaN\n",
    "Use a dot for decimals; no quotes, units, or extra text.\n",
    "\"\"\"\n",
    "\n",
    "FEW_SHOT = \"\"\"\n",
    "### EXAMPLE 1\n",
    "Field: Druck (bar/MPa)\n",
    "Product: K 2 Battery\n",
    "(Excerpt:)\n",
    "- Druck (bar/MPa): max. 110\n",
    "→ In K 2 Battery the correct Druck (bar/MPa) is 110\n",
    "\n",
    "### EXAMPLE 2\n",
    "Field: Farbe\n",
    "Product: K 7 Premium Power Flex\n",
    "(Excerpt:)\n",
    "- Gewicht ohne Zubehör (kg): 17.8\n",
    "→ In K 7 Premium Power Flex the correct Farbe is NaN\n",
    "\"\"\"\n",
    "\n",
    "prompt = (\n",
    "    BASE_SYSTEM.strip() + \"\\n\\n\" +\n",
    "    FEW_SHOT.strip() + \"\\n\\n\" +\n",
    "    f\"Field: {field}\\n\" +\n",
    "    f\"Product: {product}\\n\\n\" +\n",
    "    f\"(Contents of {product}.md below:)\\n\" +\n",
    "    md_text + \"\\n\\n\" +\n",
    "    \"→\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f8c63c-405b-4c01-b39b-3607bb2f1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_line = model.generate_text(prompt)\n",
    "print(result_line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21253794-e6ea-4758-addc-5d0aa0ccc0ed",
   "metadata": {},
   "source": [
    "As we can see, the model is halucinating even with one data imput. The actual value is **Zulauftemperatur (°C)**: max. 60. What if we try to ask the model in a promt? To reduce the possibility of an error, we use here the identical papameters and code that we used in MA3 from our group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8e129-0d55-48fc-b3e6-977d9c3e496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import WatsonxLLM\n",
    "from langchain_ibm import WatsonxLLM\n",
    "\n",
    "llm = WatsonxLLM(\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    apikey=WX_API_KEY,\n",
    "    project_id=PROJECT_ID,\n",
    "    params={\n",
    "        \"decoding_method\": \"greedy\",\n",
    "        \"temperature\": 0.0,\n",
    "        \"min_new_tokens\": 5,\n",
    "        \"max_new_tokens\": 1_000,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd1de7-a204-47d7-808a-daed51102914",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result = llm.invoke(\"Hi how are you?\")\n",
    "\n",
    "print(type(llm_result))\n",
    "print(llm_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38740eca-218f-47be-899f-05b998e1e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result = llm.invoke(\n",
    "    \"You are a product-data extractor. In the text below, locate and return the value for “Zulauftemperatur (°C)”. If the field isn’t present, respond with “Not found”.\\n\\n\"\n",
    "    \"Text:\\n\\n\"\n",
    "    \"## Page Header\\n\\n\"\n",
    "    \"The image shows the logo of Kärcher, a company known for its cleaning equipment. The logo consists of the word \\\"KÄRCHER\\\" in bold, black uppercase letters. Below the text, there is a yellow horizontal bar. The background is white, providing contrast to the black text and yellow bar. <!-- page_header, ID 77001531-ac4c-4427-8d9d-4871b3fbf695 -->\\n\\n\"\n",
    "    \"# K 5 PREMIUM SMART CONTROL FLEX eco!Booster <!-- title, ID 18485f43-17b0-4038-a9bf-5ed087e286ad -->\\n\\n\"\n",
    "    \"## Text\\n\\n\"\n",
    "    \"Für mehr Performance: der Hochdruckreiniger K 5 Premium Smart Control Flex eco!Booster mit PremiumFlex-Schlauch, G 180 Q Smart Control-Pistole, Schlauchtrommel und eco!Booster Kit. <!-- text, ID 743bca50-0296-4a44-872f-f6134441c566 -->\\n\\n\"\n",
    "    \"## Description\\n\\n\"\n",
    "    \"The image displays a Kärcher pressure washer, specifically the K5 Smart Control model. The device is predominantly yellow with black accents and features a sleek, modern design. It includes a handle for easy maneuverability and wheels for transport. The pressure washer is equipped with a hose reel for convenient storage of the hose.\\n\\n\"\n",
    "    \"### Components\\n\\n\"\n",
    "    \"- **Pressure Washer Unit**:\\n\"\n",
    "    \"  - **Color**: Yellow and black.\\n\"\n",
    "    \"  - **Model**: K5 Smart Control.\\n\"\n",
    "    \"  - **Brand**: Kärcher.\\n\"\n",
    "    \"  - **Features**:\\n\"\n",
    "    \"    - Integrated handle.\\n\"\n",
    "    \"    - Wheels for mobility.\\n\"\n",
    "    \"    - Hose reel for storage.\\n\\n\"\n",
    "    \"- **Accessories**:\\n\"\n",
    "    \"  - **Spray Gun**:\\n\"\n",
    "    \"    - Black with yellow accents.\\n\"\n",
    "    \"    - Branded with Kärcher logo.\\n\"\n",
    "    \"  - **Lance**:\\n\"\n",
    "    \"    - Black with yellow tip.\\n\"\n",
    "    \"    - Designed for various cleaning tasks.\\n\"\n",
    "    \"  - **Detergent Bottle**:\\n\"\n",
    "    \"    - Labeled \\\"Universal\\\".\\n\"\n",
    "    \"    - Features an image of a person using the pressure washer.\\n\\n\"\n",
    "    \"### Additional Details\\n\\n\"\n",
    "    \"- The pressure washer is designed for home use, suitable for cleaning cars, patios, and other surfaces.\\n\"\n",
    "    \"- The image suggests a focus on versatility and ease of use, with the inclusion of multiple attachments and a detergent bottle for enhanced cleaning performance. <!-- figure, ID dac59e3f-1a35-4150-a02f-2cf0e71df6cb -->\\n\\n\"\n",
    "    \"## Price\\n\\n\"\n",
    "    \"The image shows a price of 539,99 €. <!-- text, ID 27d5d7da-d92d-4c2d-b800-17bbfad4ad1a -->\\n\\n\"\n",
    "    \"## Text Content\\n\\n\"\n",
    "    \"inkl. MwSt. - kostenlose Lieferung ab 50 € <!-- text, ID 1a5b0407-8076-462f-9b79-cc46a8d4e8f2 -->\\n\\n\"\n",
    "    \"## Page Footer\\n\\n\"\n",
    "    \"[https://www.kaercher.com/de/home-garden/hochdruckreiniger/k-5-premium-smart-control-flex-eco-booster-13246870.html](https://www.kaercher.com/de/home-garden/hochdruckreiniger/k-5-premium-smart-control-flex-eco-booster-13246870.html) <!-- page_footer, ID 7567dd32-5f11-4cda-a5d8-5011045f6c0d -->\\n\\n\"\n",
    "    \"## Page Number\\n\\n\"\n",
    "    \"1/10 <!-- page_number, ID c25e9df6-69c3-4714-8eb0-9b4517817945 -->\\n\\n\"\n",
    "    \"## Page Header\\n\\n\"\n",
    "    \"30/04/2025, 23:44 <!-- page_header, ID 200ff78b-640d-4cb1-8ef9-6c5883e4ef6d -->\\n\\n\"\n",
    "    \"## K 5 Premium Smart Control Flex eco!Booster | Kärcher\\n\\n\"\n",
    "    \"This is a page header indicating the title of a product from Kärcher, specifically the \\\"K 5 Premium Smart Control Flex eco!Booster.\\\" <!-- page_header, ID e51076b1-3049-4369-894d-be3c7988960f -->\\n\\n\"\n",
    "    \"## Text Information\\n\\n\"\n",
    "    \"- Lieferbar in 3-4 Werktagen\\n\"\n",
    "    \"- Bestellnummer: 1.324-687.0 <!-- key_value, ID 4be821ac-2c5f-4ae2-8a20-8924b72d464c -->\\n\\n\"\n",
    "    \"## Händler Suche\\n\\n\"\n",
    "    \"- **Ort oder PLZ**: [Text input field]\\n\\n\"\n",
    "    \"### Bewertung\\n\\n\"\n",
    "    \"- **Sterne**: [ ] [ ] [ ] [ ] [ ] (0)\\n\"\n",
    "    \"- **Aktion**: Jetzt Produkt bewerten\\n\\n\"\n",
    "    \"### Produkt Optionen\\n\\n\"\n",
    "    \"- **Produkt vergleichen**: [Text link]\\n\\n\"\n",
    "    \"### Hilfe\\n\\n\"\n",
    "    \"- **Benötigen Sie Hilfe?**\\n\"\n",
    "    \"  - **Hotline**: +49 7195 903 0 <!-- form, ID 50cec018-d8bb-4273-9abc-1bad6bea78f9 -->\\n\\n\"\n",
    "    \"## Text Content\\n\\n\"\n",
    "    \"Dank integriertem Bluetooth lässt sich der Hochdruckreiniger K 5 Premium Smart Control Flex eco!Booster mit der Kärcher Home & Garden App verbinden. Die App bietet viele nützliche Funktionen wie den Anwendungsberater mit hilfreichen Tipps und Tricks, eine Aufbauanleitung, Wartungs- und Pflegehinweise sowie das Kärcher Serviceportal. Darüber hinaus verfügt das Gerät über einen Boost Mode für extra Power, G 180 Q Smart Control-Pistole mit LCD-Display und das 3-in-1-Multi Jet-Strahlrohr. Die Druckeinstellungen werden direkt an der Pistole vorgenommen oder mit Hilfe des Anwendungsberaters aus der App auf die Pistole übertragen. Über das LCD-Display lässt sich überprüfen, welche Druckstufe eingestellt ist. Weitere Ausstattungsdetails sind die Schlauchtrommel, das Plug 'n' Clean-Reinigungssystem, der PremiumFlex-Hochdruckschlauch, der Aluminium-Teleskopgriff sowie die Parkposition für jederzeit griffbereites Zubehör. Inklusive eco!Booster Kit mit eco!Booster und 1 Liter Universalreiniger. Der eco!Booster ist ideal für empfindliche Oberflächen und sorgt mit einer um 50 Prozent höheren Reinigungsleistung im Vergleich zum Flachstrahl für eine Wasser-, Energie- und Zeitersparnis. <!-- text, ID e6a43fc4-0308-4ec7-8aa5-064878973f75 -->\\n\\n\"\n",
    "    \"## Merkmale und Vorteile <!-- text, ID 8f4cbbb5-c478-495f-a400-8e93008927ce -->\\n\\n\"\n",
    "    \"## Page Number\\n\\n\"\n",
    "    \"5/10 <!-- page_number, ID 8a12ffa8-af64-4455-a64a-da610b8122d2 -->\\n\\n\"\n",
    "    \"### Page Header\\n\\n\"\n",
    "    \"- **Date and Time**: 30/04/2025, 23:44 <!-- page_header, ID 2988337e-2b21-44bd-9e82-ce3230efd6c9 -->\\n\\n\"\n",
    "    \"## K 5 Premium Smart Control Flex eco!Booster | Kärcher <!-- page_header, ID f648a450-9186-4323-b735-28539ff3487d -->\\n\\n\"\n",
    "    \"## Schlauchtrommel für komfortable Handhabung\\n\\n\"\n",
    "    \"- Der Hochdruckschlauch ist optimal geschützt und platzsparend verstaut.\\n\"\n",
    "    \"- Bequemes Arbeiten: Jederzeit griffbereiter Schlauch durch leichtes Auf- und Abrollen.\\n\"\n",
    "    \"- Tiefer Schwerpunkt für einen sicheren Stand auch auf schrägen Oberflächen. <!-- text, ID 7796f8d0-5d1d-4fb7-b8f3-7f4049ce99ed -->\\n\\n\"\n",
    "    \"## Wahrgenommene Lautstärkenreduktion\\n\\n\"\n",
    "    \"- Angenehmer Klang der Anwendung**\\n\\n\"\n",
    "    \"** Vergleich zur wahrgenommenen Lautstärke bei der Anwendung des Kärcher Standard-Flachstrahls. <!-- text, ID 16b63c93-743d-4bb8-a0a2-500169bdbed3 -->\\n\\n\"\n",
    "    \"## SPEZIFIKATIONEN\\n\\n\"\n",
    "    \"## Technische Daten\\n\\n\"\n",
    "    \"- Stromart (V/Hz): 230 / 50\\n\"\n",
    "    \"- Druck (bar/MPa): 20 - max. 145 / 2 - max. 14,5\\n\"\n",
    "    \"- Fördermenge (l/h): max. 500\\n\"\n",
    "    \"- Flächenleistung (m²/h): 40\\n\"\n",
    "    \"- Zulauftemperatur (°C): max. 60\\n\"\n",
    "    \"- Anschlussleistung (kW): 2,1\\n\"\n",
    "    \"- Anschlusskabel (m): 5\\n\"\n",
    "    \"- Farbe: gelb\\n\"\n",
    "    \"- Gewicht ohne Zubehör (kg): 13,5\\n\"\n",
    "    \"- Gewicht inkl. Verpackung (kg): 18,5\\n\"\n",
    "    \"- Abmessungen (L × B × H) (mm): 417 × 306 × 584 <!-- key_value, ID ff4355bf-a76b-40ac-a30b-21aa7848d77b -->\\n\\n\"\n",
    "    \"## Lieferumfang\\n\\n\"\n",
    "    \"- Hochdruckpistole: G 180 Q Smart Control\\n\"\n",
    "    \"- Multi Jet 3-in-1\\n\"\n",
    "    \"- eco!Booster <!-- text, ID 2050473b-7124-4cbb-8fda-9aaaf6e6f335 -->\\n\\n\"\n",
    "    \"## Page Footer\\n\\n\"\n",
    "    \"[https://www.kaercher.com/de/home-garden/hochdruckreiniger/k-5-premium-smart-control-flex-eco-booster-13246870.html](https://www.kaercher.com/de/home-garden/hochdruckreiniger/k-5-premium-smart-control-flex-eco-booster-13246870.html) <!-- page_footer, ID 29726f76-d2b3-4d03-b2b5-b77372b17c05 -->\\n\\n\"\n",
    "    \"### Page Number\\n\\n\"\n",
    "    \"6/10 <!-- page_number, ID 0b62e4cc-caff-40a0-b2b7-4b438d3c250e -->\"\n",
    ")\n",
    "print(llm_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c5efc-85c2-4602-afa2-4b651b56d861",
   "metadata": {},
   "source": [
    "As we can see, the model is halucinating even with direct data imput in the promt. The actual value is **Zulauftemperatur (°C)**: max. 60. What if we clean the markdowns and try to leave only the \"Technical Details\" like temperature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309053bf-bb3e-4cf7-a72e-4bb76b18f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd()\n",
    "src_dir      = project_root / \"parsed_markdown\"\n",
    "clean_dir    = project_root / \"parsed_markdown_clean\"\n",
    "\n",
    "clean_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f178e-6959-420e-ae3e-d222514d9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_re          = re.compile(r\"<!--.*?-->\", flags=re.DOTALL)\n",
    "blank_re            = re.compile(r\"(?:\\r?\\n){3,}\")\n",
    "remove_sections_re  = re.compile(\n",
    "    r\"^##\\s+(?:Page Header|Page Footer|Page Number)[\\s\\S]*?(?=^##\\s|\\Z)\",\n",
    "    flags=re.MULTILINE,\n",
    ")\n",
    "\n",
    "KEYS = [\n",
    "    \"Bestellnummer\",\n",
    "    \"Preis\",                 \n",
    "    \"Lieferzeit\",\n",
    "    \"Stromart\",\n",
    "    \"Druck\",\n",
    "    \"Fördermenge\",\n",
    "    \"Flächenleistung\",\n",
    "    \"Zulauftemperatur\",\n",
    "    \"Anschlussleistung\",\n",
    "    \"Anschlusskabel\",\n",
    "    \"Farbe\",\n",
    "    \"Gewicht ohne Zubehör\",\n",
    "    \"Gewicht inkl. Verpackung\",\n",
    "    \"Abmessungen\",\n",
    "]\n",
    "\n",
    "\n",
    "key_line_re = re.compile(\n",
    "    rf\"^\\s*(?:[-*]\\s*)?(?:\\*\\*|__)?(?:{'|'.join(map(re.escape, KEYS))})(?:\\b|:)\",\n",
    "    flags=re.IGNORECASE,\n",
    ")\n",
    "\n",
    "\n",
    "SECTION_TITLES = {\"Lieferumfang\", \"Ausstattung\"}\n",
    "\n",
    "for md_path in src_dir.glob(\"*.md\"):\n",
    "    raw = md_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "    txt = remove_sections_re.sub(\"\", comment_re.sub(\"\", raw))\n",
    "\n",
    "    out_lines        = []\n",
    "    keep_section     = False      \n",
    "    product_written  = False      # first non-page heading becomes Produktname\n",
    "\n",
    "    for line in txt.splitlines():\n",
    "\n",
    "        if line.startswith(\"## \"):\n",
    "            hdr = line.lstrip(\"#\").strip()\n",
    "\n",
    "\n",
    "            if not product_written:\n",
    "                prod_name = hdr.split(\"|\")[0].strip()\n",
    "                out_lines.append(\"### Produktname\")\n",
    "                out_lines.append(prod_name)\n",
    "                product_written = True\n",
    "                keep_section = False\n",
    "                continue\n",
    "\n",
    "\n",
    "            if hdr in SECTION_TITLES:\n",
    "                out_lines.append(f\"### {hdr}\")\n",
    "                keep_section = True\n",
    "            else:\n",
    "                keep_section = False\n",
    "\n",
    "            continue  \n",
    "\n",
    "        if keep_section or key_line_re.match(line):\n",
    "            out_lines.append(line)\n",
    "\n",
    "    cleaned = blank_re.sub(\"\\n\\n\", \"\\n\".join(out_lines).strip()) + \"\\n\"\n",
    "    (clean_dir / md_path.name).write_text(cleaned, encoding=\"utf-8\")\n",
    "\n",
    "print(\n",
    "    f\"Cleaned markdown saved for {len(list(src_dir.glob('*.md')))} files into {clean_dir}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af52a24b-bbf6-4d32-9bfe-49f615937f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dir = project_root / \"parsed_markdown_clean\"\n",
    "descriptions = {}\n",
    "for md in desc_dir.glob(\"*.md\"):\n",
    "    product = md.stem \n",
    "    text    = (md.read_text(encoding=\"utf-8\"))\n",
    "    descriptions[product] = text\n",
    "\n",
    "print(\"Loaded descriptions for\", len(descriptions), \"products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10736fd-5e10-4fda-b8c9-26ebfe5b5665",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert product-data imputer.\n",
    "\n",
    "Im giving you:\n",
    "\n",
    "  1. The name of exactly *one* field that is missing: {col}\n",
    "  2. The product name: {product}\n",
    "  3. A list of all *other* fields and values in the row\n",
    "  4. A full raw markdown dump\n",
    "\n",
    "Your **only** job is to return *exactly* one thing: the *value* for {col}.\n",
    "- **No** explanations, **no** punctuation around it, **no** units.\n",
    "- If you cannot confidently infer it, return **NA**.\n",
    "\n",
    "Here is the data:\n",
    "\n",
    "Field: {col}  \n",
    "Product: {product}  \n",
    "\n",
    "Known fields:  \n",
    "{other_fields}\n",
    "\n",
    "Raw markdown:  \n",
    "{markdown}\n",
    "\"\"\"\n",
    "\n",
    "# Copy your test DataFrame and locate all missing cells\n",
    "filled = df_test.copy()\n",
    "missing_locs = [\n",
    "    (i, col)\n",
    "    for i, row in df_test.iterrows()\n",
    "    for col in df_test.columns\n",
    "    if pd.isna(row[col])\n",
    "]\n",
    "\n",
    "# Helper to safely grab a number from the model’s text\n",
    "def extract_first_number(s: str) -> float:\n",
    "    m = re.search(r\"-?\\d+(?:[.,]\\d+)?\", s)\n",
    "    return float(m.group(0).replace(\",\", \".\")) if m else np.nan\n",
    "\n",
    "# Loop through each missing cell and call the model\n",
    "for (i, col) in missing_locs:\n",
    "    product = filled.at[i, \"Produktname\"] or \"\"\n",
    "    other_fields = \"\\n\".join(\n",
    "        f\"- {c}: {filled.at[i, c]}\"\n",
    "        for c in filled.columns\n",
    "        if c != col and pd.notna(filled.at[i, c])\n",
    "    )\n",
    "    raw_md = descriptions.get(product, \"\")\n",
    "\n",
    "    prompt = PROMPT_TEMPLATE.format(\n",
    "        col=col,\n",
    "        product=product,\n",
    "        other_fields=other_fields,\n",
    "        markdown=raw_md\n",
    "    )\n",
    "\n",
    "    # Send the prompt\n",
    "    resp = model.generate(prompt)\n",
    "    raw_guess = resp[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # Fill in either as a number or as raw text/NA\n",
    "    if col in numeric_cols:\n",
    "        guess = extract_first_number(raw_guess)\n",
    "    else:\n",
    "        guess = raw_guess or \"NA\"\n",
    "\n",
    "    filled.iat[i, filled.columns.get_loc(col)] = guess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913c69b-cb44-4996-ae45-475bb0c9b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i, col in missing_locs:\n",
    "    records.append({\n",
    "    'Field':   col,\n",
    "    'Imputed': filled.at[i, col],\n",
    "    'Actual':  original.at[i, col]  # ← now you grab from your unmasked copy\n",
    "})\n",
    "\n",
    "\n",
    "compare_df = pd.DataFrame(records, columns=['Field','Imputed','Actual'])\n",
    "print(compare_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f4e819-16d4-4f95-8d0d-1cf6b1214c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(compare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa8bfe-c868-4de7-83b8-13f15a96139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_counts = mismatches.groupby('Field').size().sort_values(ascending=False)\n",
    "print(error_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1944ea-b65e-4539-bf8a-10a21c092e15",
   "metadata": {},
   "source": [
    "Seems no luck for now. But can it actually extract values from a \"curated\" imput?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97c7ef-5cbc-4588-91bd-d6dcb01ff4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result = llm.invoke(\n",
    "    \"You are a product-data extractor. In the text below, locate and return the value for “Zulauftemperatur (°C)”. \" \n",
    "    \"If the field isn’t present, respond with “Not found”.\\n\\n\"\n",
    "    \"Text:\\n\"\n",
    "    \"### Technische Daten\\n\"\n",
    "    \"- Stromart (Ph/V/Hz): 1 / 230 / 50\\n\"\n",
    "    \"- Druck (bar/MPa): 20 - max. 180 / 2 - max. 18\\n\"\n",
    "    \"- Fördermenge (l/h): max. 600\\n\"\n",
    "    \"- Flächenleistung (m²/h): 60\\n\"\n",
    "    \"- Zulauftemperatur (°C): max. 60\\n\"\n",
    "    \"- Anschlussleistung (kW): 3\\n\"\n",
    "    \"- Anschlusskabel (m): 5\\n\"\n",
    "    \"- Farbe: gelb\\n\"\n",
    "    \"- Gewicht ohne Zubehör (kg): 17,3\\n\"\n",
    "    \"- Gewicht inkl. Verpackung (kg): 24\\n\"\n",
    "    \"- Abmessungen (L × B × H) (mm): 458 × 330 × 669\"\n",
    ")\n",
    "print(llm_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef37458-dbd9-4865-b2d7-aaa3f44b51e8",
   "metadata": {},
   "source": [
    "Great so our 13 Billion parameter model is working, but is to small to perform tasks designated for a quality check tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc209b-e2e7-4e88-9c89-5f69070e0a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
